{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preface\n",
    "\n",
    "In this notebook, we demonstrate classification using decision trees. We will also demonstrate model ensembling with decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('notebook', font_scale=1.25, rc={\"lines.linewidth\": 2.5})\n",
    "sns.set_style(\"darkgrid\")\n",
    "np.random.seed(123)  # For reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diabetes Dataset\n",
    "\n",
    "This dataset is originally from the *National Institute of Diabetes and Digestive and Kidney Diseases*. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\n",
    "\n",
    "The datasets consists of several medical predictor variables and one target variable, `Outcome` (1 being diabetic and 0 if not). Predictor variables includes the number of pregnancies the patient has had, their BMI, insulin level, age, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('./data/diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split\n",
    "\n",
    "We are going to split the dataset as usual. This time, we are going to apply cross validation to the training set to evaluate our model for the purpose of model selection and only use the test data for final model evaluation. This is to prevent *overfitting the test set*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = dataset[dataset.columns[:-1]], dataset[dataset.columns[-1]]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first fit a decision tree using `DecisionTreeClassifier` from `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=3)\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation Scoring\n",
    "\n",
    "We now use cross-validation scoring on the training set. This gives a better measure of the actual performance of our trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(clf, x_train, y_train, cv=10)\n",
    "print(f'Mean accuracy: {np.mean(scores)}')\n",
    "print(f'Std accuracy: {np.std(scores)}')\n",
    "sns.distplot(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that cross validated accuracies better reflect testing performance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Train accuracy: {clf.score(x_train, y_train)}')\n",
    "print(f'Mean CV accuracy: {np.mean(scores)}')\n",
    "print(f'Test accuracy: {clf.score(x_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Decision Tree\n",
    "\n",
    "As mentioned in the lecture, one advantage is that the decision tree can be visualized to see how it arrives at the decision. Let us see how our tree model arrives at a diagnosis of diabetes.\n",
    "\n",
    "We will use the `plot_tree` from `sklearn.tree` to achieve this. Alternatively, you can also use the [`graphviz` package](https://www.graphviz.org)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30, 15))\n",
    "plot_tree(\n",
    "    clf,\n",
    "    feature_names=dataset.columns[:-1],\n",
    "    class_names=['Negative', 'Positive'],\n",
    "    filled=True,\n",
    "    fontsize=25\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting\n",
    "\n",
    "Let us now fit a sequence of decision trees with increasing depth. We observe from the results below two things:\n",
    "  1. As depth increases, we overfit: training accuracy increases but not test\n",
    "  2. Generally, CV accuracy gives a better prediction of test error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for depth in range(2, 8):\n",
    "    clf = DecisionTreeClassifier(max_depth=depth)\n",
    "    clf.fit(x_train, y_train)\n",
    "    train_acc = clf.score(x_train, y_train)\n",
    "    test_acc = clf.score(x_test, y_test)\n",
    "    cv_acc = np.mean(cross_val_score(clf, x_train, y_train, cv=10))\n",
    "    results.append([depth, train_acc, test_acc, cv_acc])\n",
    "results = pd.DataFrame(\n",
    "    data=results,\n",
    "    columns=['depth', 'train accuracy', 'test accuracy', 'cv accuracy'],\n",
    ")\n",
    "results = pd.melt(\n",
    "    results,\n",
    "    id_vars=['depth'],\n",
    "    var_name='type',\n",
    "    value_name='accuracy'\n",
    ")  # Melt dataframe for easier plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(\n",
    "    x='depth',\n",
    "    y='accuracy',\n",
    "    hue='type',\n",
    "    data=results,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest (Bagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, max_depth=3)\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Train accuracy: {clf.score(x_train, y_train)}')\n",
    "scores = cross_val_score(clf, x_train, y_train, cv=10)\n",
    "print(f'Mean CV accuracy: {np.mean(scores)}')\n",
    "print(f'Test accuracy: {clf.score(x_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_rf = []\n",
    "for depth in range(2, 8):\n",
    "    clf = RandomForestClassifier(n_estimators=100, max_depth=depth)\n",
    "    clf.fit(x_train, y_train)\n",
    "    train_acc = clf.score(x_train, y_train)\n",
    "    test_acc = clf.score(x_test, y_test)\n",
    "    cv_acc = np.mean(cross_val_score(clf, x_train, y_train, cv=10))\n",
    "    results_rf.append([depth, train_acc, test_acc, cv_acc])\n",
    "results_rf = pd.DataFrame(\n",
    "    data=results_rf,\n",
    "    columns=['depth', 'train accuracy', 'test accuracy', 'cv accuracy'],\n",
    ")\n",
    "results_rf = pd.melt(\n",
    "    results_rf,\n",
    "    id_vars=['depth'],\n",
    "    var_name='type',\n",
    "    value_name='accuracy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 4), sharey=True)\n",
    "\n",
    "sns.lineplot(\n",
    "    x='depth',\n",
    "    y='accuracy',\n",
    "    hue='type',\n",
    "    data=results,\n",
    "    ax=ax[0]\n",
    ")\n",
    "ax[0].set_title('Decision Tree')\n",
    "\n",
    "sns.lineplot(\n",
    "    x='depth',\n",
    "    y='accuracy',\n",
    "    hue='type',\n",
    "    data=results_rf,\n",
    "    ax=ax[1]\n",
    ")\n",
    "ax[1].set_title('Random Forest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost (Boosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=1),\n",
    "    n_estimators=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Train accuracy: {clf.score(x_train, y_train)}')\n",
    "scores = cross_val_score(clf, x_train, y_train, cv=10)\n",
    "print(f'Mean CV accuracy: {np.mean(scores)}')\n",
    "print(f'Test accuracy: {clf.score(x_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-parameter Tuning\n",
    "\n",
    "Observe that there are many choices in the `AdaBoost` classifier. We have mostly left everything to their default values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, however, to obtain good performance we should perform *hyper-parameter tuning*. This means that we should pick the parameters (e.g. `max_depth`, `criterion`, `learning_rate`, `n_estimators` etc) to maximize performance. \n",
    "\n",
    "How do we judge performance? We use cross-validation on the training set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we check what parameters are adjustable using `clf.get_params()`. \n",
    "\n",
    "**Note: make sure you understand what these parameters mean!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we set up parameter grids and apply `GridSearchCV`. This will take some time..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'base_estimator__max_depth': [1, 2, 3],\n",
    "    'base_estimator__criterion': ['gini', 'entropy'],\n",
    "    'n_estimators': [5, 25, 50],\n",
    "    'learning_rate': [0.01, 0.1, 1.0],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_grid = GridSearchCV(estimator=clf, param_grid=param_grid, cv=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the ``cv`` argument is the number of folds of cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Train accuracy: {clf_grid.score(x_train, y_train)}')\n",
    "print(f'Test accuracy: {clf_grid.score(x_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Remarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have improved our results by cross-validation grid search over some hyper-parameters. What if the parameter space is very large so that grid search is impossible? You may check `sklearn.model_selection.RandomizedSearchCV`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another boosting algorithm, namely *gradient boosting*, typically gives state of the art results on a variety of tasks. For details, check the following resources:\n",
    "   * [Gradient boosting on sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html)\n",
    "   * [xgboost](https://xgboost.readthedocs.io/en/latest/python/python_intro.html): another implementation, generally faster/better than sklearn's\n",
    "   \n",
    "Remember to perform hyperparameter tuning! The defaults can be very bad for some applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
